{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the original data and produce datasets accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pd.read_csv('./data/prad_Liu_FPKM_1.5CPMcutoff.csv')\n",
    "data2 = pd.read_csv('./data/prad_Liu_FPKM_2CPMcutoff.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_names = []\n",
    "for df, name  in zip([data1,data2],['1_5_CPMcutoff','2_0_CPMcutoff']):\n",
    "    for col_suffix in ['_1','_2','_3']:\n",
    "        new_name = './data/{}_suffix{}.csv'.format(name,col_suffix)\n",
    "        log_new_name = './data/{}_suffix{}_log.csv'.format(name,col_suffix)\n",
    "        new_names.append(new_name)\n",
    "        new_names.append(log_new_name)\n",
    "        foo = df[\n",
    "            df.columns[\n",
    "                pd.Series(df.columns).str.endswith(col_suffix) |\n",
    "                pd.Series(df.columns).str.contains('gene')\n",
    "            ]\n",
    "        ].copy()        \n",
    "        foo.to_csv(new_name, index = False)\n",
    "        for col in foo.columns[1:] :\n",
    "            foo[col] = np.log(foo[col]+1)\n",
    "        foo.to_csv(log_new_name, index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make additional databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_suffix_to_csv_name (filename, suffix):\n",
    "    return '.'.join(filename.split('.')[:-1])+suffix+'.csv'\n",
    "log_names = new_names[1::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminate rows with data 0\n",
    "for name in log_names:\n",
    "    data_aux = pd.read_csv(name)\n",
    "    new_name = add_suffix_to_csv_name(filename = name, suffix = '_non_cero')\n",
    "    min_element = np.min(data_aux.iloc[:,1:].values,axis = 1)\n",
    "    data_aux = data_aux[min_element >0]    \n",
    "    data_aux.to_csv(new_name, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum element different than cero in row C42_1\t: 0.0013643493807682\n",
      "Minimum element different than cero in row C42B_1\t: 0.0059937805666761\n",
      "Minimum element different than cero in row LNCAP_1\t: 0.0083357247789965\n",
      "Minimum element different than cero in row C42_2\t: 0.0108543613728212\n",
      "Minimum element different than cero in row C42B_2\t: 0.0075410332405337\n",
      "Minimum element different than cero in row LNCAP_2\t: 0.0064330522178986\n",
      "Minimum element different than cero in row C42_3\t: 0.0072149244835187\n",
      "Minimum element different than cero in row C42B_3\t: 0.0123872395970258\n",
      "Minimum element different than cero in row LNCAP_3\t: 0.0106072226024647\n",
      "Minimum element different than cero in row C42_1\t: 0.0005085017078234\n",
      "Minimum element different than cero in row C42B_1\t: 0.0069791748025771\n",
      "Minimum element different than cero in row LNCAP_1\t: 0.0072060846933321\n",
      "Minimum element different than cero in row C42_2\t: 0.0090361091194049\n",
      "Minimum element different than cero in row C42B_2\t: 0.0069880108790442\n",
      "Minimum element different than cero in row LNCAP_2\t: 0.0059193549991681\n",
      "Minimum element different than cero in row C42_3\t: 0.0141741714339257\n",
      "Minimum element different than cero in row C42B_3\t: 0.0089855735481899\n",
      "Minimum element different than cero in row LNCAP_3\t: 0.0038815221368447\n"
     ]
    }
   ],
   "source": [
    "# Eliminate rows with data 0\n",
    "for name in log_names:\n",
    "    data_aux = pd.read_csv(name)\n",
    "    new_name = add_suffix_to_csv_name(filename = name, suffix = '_cero_replacement')\n",
    "    for col in range(1,4):\n",
    "        min_element = np.min(data_aux[data_aux.columns[col]][data_aux.iloc[:,col]>0])\n",
    "        print('Minimum element different than cero in row {}\\t: {}'.format(data_aux.columns[col],min_element))\n",
    "        for row in range(len(data_aux)):\n",
    "            if data_aux.iloc[row,col] == 0 :\n",
    "                data_aux.iloc[row,col] = np.random.uniform(0,min_element)\n",
    "    data_aux.to_csv(new_name, index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
